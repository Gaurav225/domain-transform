\section{Introduction}\label{sec:intro}
\fixme{Review}

Filtering operations are often a crucial step of image processing. In
particular, most useful filter options are edge-aware smoothing filters, 
whose output can be used as a building block for multiple other applications.
For example, such filters can be used to extract or remove features from an
image, to colorize the image in a intuitive fashion by colouring specific
items on an image, as well as perform other tasks such as noise removal and
image compression.

As in most cases with image (and in particular with video) processing, it is
highly required that the filters have a low computational cost and therefore
can produce fast results, especially when used for real-time transformation of
graphical data. It is also true that image recording technologies advance and 
therefore can create images of greater resolution, which means an increase in
the amount of computation needed for filtering. And lastly images are 2D data
and will have to be processed both horizontally and vertically, which makes
spatial locality troublecome.

There exist multiple algorithms that perform this type of filtering, however
most of these are computationally heavy and almost impossible to execute in
real-time. Moreover, some of those only naturally support grayscale images. \fixme{should we add references here?}
For this project we have picked one of the fastest known algorithms for the
task in question, which works on full RGB images.

The main idea of this fast approach is to use a domain transformation on the
image which allows to reduce the dimensionality of the data. An RGB image in
essence is a 2D manifold in 5D space, and an edge-preserving filter can be
defined in lower dimensions as long as the 5D distances among the pixels are
preserved. The transformation defines an isometry between curves on the 2D
manifold and the real line. It preserves the geodesic distance between points
on the curve wrapping the image into two 1D domains, one for horizontal 
distances and one for vertical. Then a 1D edge-preserving filter can be ran on
this transformed domain.

The work presented here aims at optimizing the implementation of on of the 
more sophisticated algorithm versions on the CPU. The only publicly available
implementation of it is in MATLAB, and is useless for fast prosessing of image
data. We have implemented the algorith in C/C++ and proceeded to use the
techniques described in the course to improve its performance.

\comment{Do not start the introduction with the abstract or a slightly modified
version. It follows a possible structure of the introduction. 
Note that the structure can be modified, but the
content should be the same. Introduction and abstract should fill at most the first page, better less.

\mypar{Motivation} The first task is to motivate what you do.  You can
start general and zoom in one the specific problem you consider.  In
the process you should have explained to the reader: what you are doing,
why you are doing, why it is important (order is usually reversed).

For example, if my result is the fastest DFT implementation ever, one
could roughly go as follows. First explain why the DFT is important
(used everywhere with a few examples) and why performance matters (large datasets,
realtime). Then explain that fast implementations are very hard and
expensive to get (memory hierarchy, vector, parallel). 

Now you state what you do in this paper. In our example: 
presenting a DFT implementation that is
faster for some sizes than all the other ones.

\mypar{Related work} Next, you have to give a brief overview of
related work. For a paper like this, anywhere between 2 and 8
references. Briefly explain what they do. In the end contrast to what
you do to make now precisely clear what your contribution is.
}